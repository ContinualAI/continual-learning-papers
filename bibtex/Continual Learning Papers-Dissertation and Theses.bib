
@phdthesis{aljundi2019,
  title = {Continual {{Learning}} in {{Neural Networks}}},
  author = {Aljundi, Rahaf},
  year = {2019},
  journal = {arXiv},
  number = {September},
  url = {https://arxiv.org/abs/1910.02718},
  abstract = {Artificial neural networks have exceeded human-level performance in accomplishing several individual tasks (e.g. voice recognition, object recognition, and video games). However, such success remains modest compared to human intelligence that can learn and perform an unlimited number of tasks. Humans' ability of learning and accumulating knowledge over their lifetime is an essential aspect of their intelligence. Continual machine learning aims at a higher level of machine intelligence through providing the artificial agents with the ability to learn online from a non-stationary and never-ending stream of data. A key component of such a never-ending learning process is to overcome the catastrophic forgetting of previously seen data, a problem that neural networks are well known to suffer from. The work described in this thesis has been dedicated to the investigation of continual learning and solutions to mitigate the forgetting phenomena in neural networks. To approach the continual learning problem, we first assume a task incremental setting where tasks are received one at a time and data from previous tasks are not stored. Since the task incremental setting can't be assumed in all continual learning scenarios, we also study the more general online continual setting. We consider an infinite stream of data drawn from a non-stationary distribution with a supervisory or self-supervisory training signal. The proposed methods in this thesis have tackled important aspects of continual learning. They were evaluated on different benchmarks and over various learning sequences. Advances in the state of the art of continual learning have been shown and challenges for bringing continual learning into application were critically identified.},
  school = {KU Leuven},
  keywords = {[cifar],[imagenet],[mnist],[vision],\#nosource}
}

@phdthesis{belouadah2021,
  title = {Large-Scale Deep Class-Incremental Learning. ({{Apprentissage}} Incr\'emental Profond \`a Large \'Echelle)},
  author = {Belouadah, Eden},
  year = {2021},
  url = {https://tel.archives-ouvertes.fr/tel-03478553},
  school = {Ecole nationale sup\'erieure Mines-T\'el\'ecom Atlantique, France},
  keywords = {/unread}
}

@phdthesis{fayek2019,
  title = {Continual {{Deep Learning}} via {{Progressive Learning}}},
  author = {Fayek, Haytham M.},
  year = {2019},
  journal = {RMIT University},
  url = {http://researchbank.rmit.edu.au/eserv/rmit:162646/Fayek.pdf},
  abstract = {Machine learning is one of several approaches to artificial intelligence. It allows us to build machines that can learn from experience as opposed to being explicitly programmed. Current machine learning formulations are mostly designed for learning and performing a particular task from a tabula rasa using data available for that task. For machine learning to converge to artificial intelligence, in addition to other desiderata, it must be in a state of continual learning, i.e., have the ability to be in a continuous learning process, such that when a new task is presented, the system can leverage prior knowledge from prior tasks, in learning and performing this new task, and augment the prior knowledge with the newly acquired knowledge without having a significant adverse effect on the prior knowledge. Continual learning is key to advancing machine learning and artificial intelligence. Deep learning is a powerful general-purpose approach to machine learning that is able to solve numerous and various tasks with minimal modification. Deep learning extends machine learning, and specially neural networks, to learn multiple levels of distributed representations together with the required mapping function into a single composite function. The emergence of deep learning and neural networks as a generic approach to machine learning, coupled with their ability to learn versatile hierarchical representations, has paved the way for continual learning. The main aim of this thesis is the study and development of a structured approach to continual learning, leveraging the success of deep learning and neural networks. This thesis studies the application of deep learning to a number of supervised learning tasks, and in particular, classification tasks in machine perception, e.g., image recognition, automatic speech recognition, and speech emotion recognition. The relation between the systems developed for these tasks is investigated to illuminate the layer-wise relevance of features in deep networks trained for these tasks via transfer learning, and these independent systems are unified into continual learning systems. The main contribution of this thesis is the construction and formulation of a deep learning framework, denoted progressive learning, that allows a holistic and systematic approach to continual learning. Progressive learning comprises a number of procedures that address the continual learning desiderata. It is shown that, when tasks are related, progressive learning leads to faster learning that converges to better generalization performance using less amounts of data and a smaller number of dedicated parameters, for the tasks studied in this thesis, by accumulating and leveraging knowledge learned across tasks in a continuous manner. It is envisioned that progressive learning is a step towards a fully general continual learning framework.},
  school = {RMIT University},
  keywords = {[audio],[cifar],[imagenet],[sparsity],\#nosource}
}

@phdthesis{henning2022,
  type = {Doctoral {{Thesis}}},
  title = {Knowledge Uncertainty and Lifelong Learning in Neural Systems},
  author = {Henning, Christian},
  year = {2022},
  doi = {10.3929/ethz-b-000523790},
  url = {https://www.research-collection.ethz.ch/handle/20.500.11850/523790},
  urldate = {2022-03-07},
  copyright = {http://rightsstatements.org/page/InC-NC/1.0/},
  langid = {english},
  school = {ETH Zurich},
  annotation = {Accepted: 2022-03-07T06:53:40Z}
}

@phdthesis{lesort2020a,
  title = {Continual {{Learning}}: {{Tackling Catastrophic Forgetting}} in {{Deep Neural Networks}} with {{Replay Processes}}},
  author = {Lesort, Timoth'ee},
  year = {2020},
  journal = {arXiv},
  url = {http://arxiv.org/abs/2007.00487},
  abstract = {Humans learn all their life long. They accumulate knowledge from a sequence of learning experiences and remember the essential concepts without forgetting what they have learned previously. Artificial neural networks struggle to learn similarly. They often rely on data rigorously preprocessed to learn solutions to specific problems such as classification or regression. In particular, they forget their past learning experiences if trained on new ones. Therefore, artificial neural networks are often inept to deal with real-life settings such as an autonomous-robot that has to learn on-line to adapt to new situations and overcome new problems without forgetting its past learning-experiences. Continual learning (CL) is a branch of machine learning addressing this type of problem. Continual algorithms are designed to accumulate and improve knowledge in a curriculum of learning-experiences without forgetting. In this thesis, we propose to explore continual algorithms with replay processes. Replay processes gather together rehearsal methods and generative replay methods. Generative Replay consists of regenerating past learning experiences with a generative model to remember them. Rehearsal consists of saving a core-set of samples from past learning experiences to rehearse them later. The replay processes make possible a compromise between optimizing the current learning objective and the past ones enabling learning without forgetting in sequences of tasks settings. We show that they are very promising methods for continual learning. Notably, they enable the re-evaluation of past data with new knowledge and the confrontation of data from different learning-experiences. We demonstrate their ability to learn continually through unsupervised learning, supervised learning and reinforcement learning tasks.},
  school = {EnstaParis Tech},
  keywords = {[cifar],[framework],[generative],[mnist],[vision],\#nosource},
  annotation = {\_eprint: 2007.00487},
  note = {This dissertation constitutes a valid summary of the latest effort in the use of generative models for continual learning and vice-versa.}
}

@phdthesis{lomonaco2019,
  title = {{Continual Learning with Deep Architectures}},
  author = {Lomonaco, Vincenzo},
  year = {2019},
  journal = {University of Bologna},
  doi = {10.6092/unibo/amsdottorato/9073},
  url = {http://amsdottorato.unibo.it/9073/},
  abstract = {Humans have the extraordinary ability to learn continually from experience. Not only we can apply previously learned knowledge and skills to new situations, we can also use these as the foundation for later learning. One of the grand goals of Artificial Intelligence (AI) is building an artificial ``continual learning'' agent that constructs a sophisticated understanding of the world from its own experience through the autonomous incremental development of ever more complex knowledge and skills. However, despite early speculations and few pioneering works, very little research and effort has been devoted to address this vision. Current AI systems greatly suffer from the exposure to new data or environments which even slightly differ from the ones for which they have been trained for. Moreover, the learning process is usually constrained on fixed datasets within narrow and isolated tasks which may hardly lead to the emergence of more complex and autonomous intelligent behaviors. In essence, continual learning and adaptation capabilities, while more than often thought as fundamental pillars of every intelligent agent, have been mostly left out of the main AI research focus. In this dissertation, we study the application of these ideas in light of the more recent advances in machine learning research and in the context of deep architectures for AI. We propose a comprehensive and unifying framework for continual learning, new metrics, benchmarks and algorithms, as well as providing substantial experimental evaluations in different supervised, unsupervised and reinforcement learning tasks.},
  langid = {italian},
  school = {alma},
  keywords = {[core50],[framework],\#nosource}
}

@phdthesis{ring1994,
  title = {Continual {{Learning}} in {{Reinforcement Environments}}},
  author = {Ring, Mark},
  year = {1994},
  journal = {University of Texas},
  volume = {1},
  url = {https://www.cs.utexas.edu/ ring/Ring-dissertation.pdf},
  abstract = {Continual learning is the constant development of complex behaviors with no final end in mind. It is the process of learning ever more complicated skills by building on those skills already developed. In order for learning at one stage of development to serve as the foundation for later learning, a continual-learning agent should learn hierarchically. CHILD, an agent capable of Continual, Hierarchical, Incremental Learning and Development is proposed, described, tested, and evaluated in this dissertation. CHILD accumulates useful behaviors in reinforcement environments by using the Temporal Transition Hierarchies learning algorithm, also derived in the dissertation. This constructive algorithm generates a hierarchical, higher-order neural network that can be used for predicting context-dependent temporal sequences and can learn sequential-task benchmarks more than two orders of magnitude faster than competing neural network systems. Consequently, CHILD can quickly solve complicated non-Markovian reinforcement-learning tasks and can then transfer its skills to similar but even more complicated tasks, learning these faster still. This continual-learning approach is made possible by the unique properties of Temporal Transition Hierarchies, which allow existing skills to be amended and augmented in precisely the same way that they were constructed in the first place.},
  school = {University of Texas},
  keywords = {[framework],\#nosource}
}

@book{thrun1996,
  title = {Explanation-{{Based Neural Network Learning}}: {{A Lifelong Learning Approach}}},
  author = {Thrun, Sebastian},
  year = {1996},
  publisher = {{Springer}},
  url = {https://www.springer.com/gp/book/9780792397168},
  abstract = {Lifelong learning addresses situations in which a learner faces a series of different learning tasks providing the opportunity for synergy among them. Explanation-based neural network learning (EBNN) is a machine learning algorithm that transfers knowledge across multiple learning tasks. When faced with a new learning task, EBNN exploits domain knowledge accumulated in previous learning tasks to guide generalization in the new one. As a result, EBNN generalizes more accurately from less data than comparable methods. Explanation-Based Neural Network Learning: A Lifelong Learning Approach describes the basic EBNN paradigm and investigates it in the context of supervised learning, reinforcement learning, robotics, and chess. `The paradigm of lifelong learning - using earlier learned knowledge to improve subsequent learning - is a promising direction for a new generation of machine learning algorithms. Given the need for more accurate learning methods, it is difficult to imagine a future for machine learning that does not include this paradigm.' From the Foreword by Tom M. Mitchell.},
  isbn = {978-1-4612-8597-7},
  keywords = {[framework],\#nosource}
}


