
@article{rostami2019,
  title = {Complementary {{Learning}} for {{Overcoming Catastrophic Forgetting Using Experience Replay}}},
  author = {Rostami, Mohammad and Kolouri, Soheil and Pilly, Praveen K},
  year = {2019},
  journal = {arXiv},
  url = {http://arxiv.org/abs/1903.04566},
  abstract = {Despite huge success, deep networks are unable to learn effectively in sequential multitask learning settings as they forget the past learned tasks after learning new tasks. Inspired from complementary learning systems theory, we address this challenge by learning a generative model that couples the current task to the past learned tasks through a discriminative embedding space. We learn an abstract level generative distribution in the embedding that allows the generation of data points to represent the experience. We sample from this distribution and utilize experience replay to avoid forgetting and simultaneously accumulate new knowledge to the abstract distribution in order to couple the current task with past experience. We demonstrate theoretically and empirically that our framework learns a distribution in the embedding that is shared across all task and as a result tackles catastrophic forgetting.},
  keywords = {⛔ No DOI found},
  annotation = {\_eprint: 1903.04566}
}

@inproceedings{shin2017,
  title = {Continual {{Learning}} with {{Deep Generative Replay}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 30},
  author = {Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
  editor = {Guyon, I and Luxburg, U V and Bengio, S and Wallach, H and Fergus, R and Vishwanathan, S and Garnett, R},
  year = {2017},
  pages = {2990--2999},
  publisher = {{Curran Associates, Inc.}},
  url = {http://papers.nips.cc/paper/6892-continual-learning-with-deep-generative-replay.pdf},
  keywords = {[mnist],⛔ No DOI found}
}

@article{vandeven2018a,
  title = {Generative Replay with Feedback Connections as a General Strategy for Continual Learning},
  author = {{van de Ven}, Gido M. and Tolias, Andreas S.},
  year = {2018},
  journal = {arXiv},
  url = {https://arxiv.org/abs/1809.10635},
  abstract = {A major obstacle to developing artificial intelligence applications capable of true lifelong learning is that artificial neural networks quickly or catastrophically forget previously learned tasks when trained on a new one. Numerous methods for alleviating catastrophic forgetting are currently being proposed, but differences in evaluation protocols make it difficult to directly compare their performance. To enable more meaningful comparisons, here we identified three distinct scenarios for continual learning based on whether task identity is known and, if it is not, whether it needs to be inferred. Performing the split and permuted MNIST task protocols according to each of these scenarios, we found that regularization-based approaches (e.g., elastic weight consolidation) failed when task identity needed to be inferred. In contrast, generative replay combined with distillation (i.e., using class probabilities as "soft targets") achieved superior performance in all three scenarios. Addressing the issue of efficiency, we reduced the computational cost of generative replay by integrating the generative model into the main model by equipping it with generative feedback or backward connections. This Replay-through-Feedback approach substantially shortened training time with no or negligible loss in performance. We believe this to be an important first step towards making the powerful technique of generative replay scalable to real-world continual learning applications.},
  keywords = {[framework],[generative],[mnist],⛔ No DOI found},
  annotation = {\_eprint: 1809.10635}
}

@article{vandeven2020a,
  title = {Brain-Inspired Replay for Continual Learning with Artificial Neural Networks},
  author = {{van de Ven}, Gido M. and Siegelmann, Hava T. and Tolias, Andreas S.},
  year = {2020},
  journal = {Nature Communications},
  volume = {11},
  doi = {10.1038/s41467-020-17866-2},
  url = {https://www.nature.com/articles/s41467-020-17866-2},
  abstract = {Artificial neural networks suffer from catastrophic forgetting. Unlike humans, when these networks are trained on something new, they rapidly forget what was learned before. In the brain, a mechanism thought to be important for protecting memories is the reactivation of neuronal activity patterns representing those memories. In artificial neural networks, such memory replay can be implemented as `generative replay', which can successfully \textendash{} and surprisingly efficiently \textendash{} prevent catastrophic forgetting on toy examples even in a class-incremental learning scenario. However, scaling up generative replay to complicated problems with many tasks or complex inputs is challenging. We propose a new, brain-inspired variant of replay in which internal or hidden representations are replayed that are generated by the network's own, context-modulated feedback connections. Our method achieves state-of-the-art performance on challenging continual learning benchmarks (e.g., class-incremental learning on CIFAR-100) without storing data, and it provides a novel model for replay in the brain.},
  keywords = {[cifar],[framework],[generative],[mnist]},
  note = {The paper shows a generative form of replay in which a VAE, conditioned on the current task, is able to generate pseudosamples and, when used as a classifier, to address new tasks. The idea is that the generative model is inspired by the hyppocampus, which sits hierarchically on top of the cortex (often thought as the classifier). In this way, replay is fed-back by the same model used to predict the class. Forgetting is prevented both on VAE and on the classification component through replay. It also shows that regularization approaches fail in class-incremental setting.}
}

@article{wang2019,
  title = {Continual {{Learning}} of {{New Sound Classes}} Using {{Generative Replay}}},
  author = {Wang, Zhepei and Subakan, Cem and Tzinis, Efthymios and Smaragdis, Paris and Charlin, Laurent},
  year = {2019},
  journal = {arXiv},
  url = {http://arxiv.org/abs/1906.00654},
  abstract = {Continual learning consists in incrementally training a model on a sequence of datasets and testing on the union of all datasets. In this paper, we examine continual learning for the problem of sound classification, in which we wish to refine already trained models to learn new sound classes. In practice one does not want to maintain all past training data and retrain from scratch, but naively updating a model with new data(sets) results in a degradation of already learned tasks, which is referred to as "catastrophic forgetting." We develop a generative replay procedure for generating training audio spectrogram data, in place of keeping older training datasets. We show that by incrementally refining a classifier with generative replay a generator that is 4\% of the size of all previous training data matches the performance of refining the classifier keeping 20\% of all previous training data. We thus conclude that we can extend a trained sound classifier to learn new classes without having to keep previously used datasets.},
  keywords = {[audio],⛔ No DOI found,audio,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio,sequence,sequences,Statistics - Machine Learning,time series},
  note = {arXiv: 1906.00654
\par
arXiv: 1906.00654}
}


