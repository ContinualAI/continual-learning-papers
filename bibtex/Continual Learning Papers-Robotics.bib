
@article{ayub2020b,
  title = {Tell Me What This Is: {{Few}}-{{Shot Incremental Object Learning}} by a {{Robot}}},
  author = {Ayub, Ali and Wagner, Alan R.},
  year = {2020},
  journal = {arXiv},
  url = {http://arxiv.org/abs/2008.00819},
  abstract = {For many applications, robots will need to be incrementally trained to recognize the specific objects needed for an application. This paper presents a practical system for incrementally training a robot to recognize different object categories using only a small set of visual examples provided by a human. The paper uses a recently developed state-of-the-art method for few-shot incremental learning of objects. After learning the object classes incrementally, the robot performs a table cleaning task organizing objects into categories specified by the human. We also demonstrate the system's ability to learn arrangements of objects and predict missing or incorrectly placed objects. Experimental evaluations demonstrate that our approach achieves nearly the same performance as a system trained with all examples at one time (batch training), which constitutes a theoretical upper bound.},
  keywords = {catastrophic forgetting,continual learning,few-shot incremenatl learning,robotics},
  annotation = {\_eprint: 2008.00819}
}

@inproceedings{dehghan2019,
  title = {Online {{Object}} and {{Task Learning}} via {{Human Robot Interaction}}},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Dehghan, M. and Zhang, Z. and Siam, M. and Jin, J. and Petrich, L. and Jagersand, M.},
  year = {2019},
  url = {https://arxiv.org/abs/1809.08722},
  abstract = {This work describes the development of a robotic system that acquires knowledge incrementally through human interaction where new tools and motions are taught on the fly. The robotic system developed was one of the five finalists in the KUKA Innovation Award competition and demonstrated during the Hanover Messe 2018 in Germany. The main contributions of the system are a) a novel incremental object learning module - a deep learning based localization and recognition system - that allows a human to teach new objects to the robot, b) an intuitive user interface for specifying 3D motion task associated with the new object, c) a hybrid force-vision control module for performing compliant motion on an unstructured surface. This paper describes the implementation and integration of the main modules of the system and summarizes the lessons learned from the competition.}
}

@inproceedings{mitchell1993,
  title = {Explanation-{{Based Neural Network Learning}} for {{Robot Control}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 5},
  author = {Mitchell, Tom M and Thrun, Sebastian B},
  year = {1993},
  url = {https://papers.nips.cc/paper/614-explanation-based-neural-network-learning-for-robot-control.pdf},
  abstract = {How can artificial neural nets generalize better from fewer examples? In order to generalize successfully, neural network learning methods typically require large training data sets. We introduce a neural network learning method that generalizes rationally from many fewer data points, relying instead on prior knowledge encoded in previously learned neural networks. For example, in robot control learning tasks reported here, previously learned networks that model the effects of robot actions are used to guide subsequent learning of robot control functions. For each observed training example of the target function (e.g. the robot control policy), the learner explains the observed example in terms of its prior knowledge, then analyzes this explanation to infer additional information about the shape, or slope, of the target function. This shape knowledge is used to bias generalization when learning the target function. Results are presented applying this approach to a simulated robot task based on reinforcement learning.}
}

@incollection{thrun1995,
  title = {A {{Lifelong Learning Perspective}} for {{Mobile Robot Control}}},
  booktitle = {Intelligent {{Robots}} and {{Systems}}},
  author = {Thrun, Sebastian},
  editor = {Graefe, Volker},
  year = {1995},
  pages = {201--214},
  publisher = {{Elsevier Science B.V.}},
  address = {{Amsterdam}},
  doi = {10.1016/B978-044482250-5/50015-3},
  abstract = {Designing robots that learn by themselves to perform complex real-world tasks is a still-open challenge for the field of robotics and artificial intelligence. This chapter presents the robot learning problem as a lifelong problem, in which a robot faces a collection of tasks over its entire lifetime. Such a scenario provides the opportunity to gather general-purpose knowledge that transfers across tasks. The chapter illustrates a learning mechanism, explanation-based neural-network learning, that transfers knowledge between related tasks via neural-network action models. The learning approach is illustrated using a mobile robot, equipped with visual, ultrasonic, and laser sensors. In less than 10 minutes of operation time, the robot is able to learn to navigate to a marked target object in a natural office environment.},
  isbn = {978-0-444-82250-5},
  language = {en}
}

@article{wong2016,
  title = {Towards {{Lifelong Self}}-{{Supervision}}: {{A Deep Learning Direction}} for {{Robotics}}},
  author = {Wong, Jay M},
  year = {2016},
  journal = {arXiv},
  url = {http://arxiv.org/abs/1611.00201},
  abstract = {Despite outstanding success in vision amongst other domains, many of the recent deep learning approaches have evident drawbacks for robots. This manuscript surveys recent work in the literature that pertain to applying deep learning systems to the robotics domain, either as means of estimation or as a tool to resolve motor commands directly from raw percepts. These recent advances are only a piece to the puzzle. We suggest that deep learning as a tool alone is insufficient in building a unified framework to acquire general intelligence. For this reason, we complement our survey with insights from cognitive development and refer to ideas from classical control theory, producing an integrated direction for a lifelong learning architecture.},
  keywords = {autonomy,cognition,deep learning,lifelong learning,robotics},
  annotation = {\_eprint: 1611.00201}
}


