
@article{ayub2020b,
  title = {Tell Me What This Is: {{Few-Shot Incremental Object Learning}} by a {{Robot}}},
  author = {Ayub, Ali and Wagner, Alan R.},
  year = {2020},
  journal = {arXiv},
  url = {http://arxiv.org/abs/2008.00819},
  abstract = {For many applications, robots will need to be incrementally trained to recognize the specific objects needed for an application. This paper presents a practical system for incrementally training a robot to recognize different object categories using only a small set of visual examples provided by a human. The paper uses a recently developed state-of-the-art method for few-shot incremental learning of objects. After learning the object classes incrementally, the robot performs a table cleaning task organizing objects into categories specified by the human. We also demonstrate the system's ability to learn arrangements of objects and predict missing or incorrectly placed objects. Experimental evaluations demonstrate that our approach achieves nearly the same performance as a system trained with all examples at one time (batch training), which constitutes a theoretical upper bound.},
  keywords = {/unread,\#nosource,⛔ No DOI found,catastrophic forgetting,continual learning,few-shot incremenatl learning,robotics},
  annotation = {\_eprint: 2008.00819}
}

@inproceedings{dehghan2019,
  title = {Online {{Object}} and {{Task Learning}} via {{Human Robot Interaction}}},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Dehghan, M. and Zhang, Z. and Siam, M. and Jin, J. and Petrich, L. and Jagersand, M.},
  year = {2019},
  doi = {10/gnq33h},
  url = {https://arxiv.org/abs/1809.08722},
  abstract = {This work describes the development of a robotic system that acquires knowledge incrementally through human interaction where new tools and motions are taught on the fly. The robotic system developed was one of the five finalists in the KUKA Innovation Award competition and demonstrated during the Hanover Messe 2018 in Germany. The main contributions of the system are a) a novel incremental object learning module - a deep learning based localization and recognition system - that allows a human to teach new objects to the robot, b) an intuitive user interface for specifying 3D motion task associated with the new object, c) a hybrid force-vision control module for performing compliant motion on an unstructured surface. This paper describes the implementation and integration of the main modules of the system and summarizes the lessons learned from the competition.},
  keywords = {/unread,\#nosource}
}

@article{hayes2022,
  title = {Online {{Continual Learning}} for {{Embedded Devices}}},
  author = {Hayes, Tyler L. and Kanan, Christopher},
  year = {2022},
  journal = {arXiv},
  eprint = {2203.10681},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2203.10681},
  urldate = {2022-03-26},
  abstract = {Real-time on-device continual learning is needed for new applications such as home robots, user personalization on smartphones, and augmented/virtual reality headsets. However, this setting poses unique challenges: embedded devices have limited memory and compute capacity and conventional machine learning models suffer from catastrophic forgetting when updated on non-stationary data streams. While several online continual learning models have been developed, their effectiveness for embedded applications has not been rigorously studied. In this paper, we first identify criteria that online continual learners must meet to effectively perform real-time, on-device learning. We then study the efficacy of several online continual learning methods when used with mobile neural networks. We measure their performance, memory usage, compute requirements, and ability to generalize to out-of-domain inputs.},
  archiveprefix = {arXiv},
  keywords = {/unread,⛔ No DOI found,Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
}

@inproceedings{mitchell1993,
  title = {Explanation-{{Based Neural Network Learning}} for {{Robot Control}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 5},
  author = {Mitchell, Tom M and Thrun, Sebastian B},
  year = {1993},
  url = {https://papers.nips.cc/paper/614-explanation-based-neural-network-learning-for-robot-control.pdf},
  abstract = {How can artificial neural nets generalize better from fewer examples? In order to generalize successfully, neural network learning methods typically require large training data sets. We introduce a neural network learning method that generalizes rationally from many fewer data points, relying instead on prior knowledge encoded in previously learned neural networks. For example, in robot control learning tasks reported here, previously learned networks that model the effects of robot actions are used to guide subsequent learning of robot control functions. For each observed training example of the target function (e.g. the robot control policy), the learner explains the observed example in terms of its prior knowledge, then analyzes this explanation to infer additional information about the shape, or slope, of the target function. This shape knowledge is used to bias generalization when learning the target function. Results are presented applying this approach to a simulated robot task based on reinforcement learning.},
  keywords = {/unread,\#nosource,⛔ No DOI found}
}

@article{pique2022,
  title = {Controlling {{Soft Robotic Arms Using Continual Learning}}},
  author = {Piqu{\'e}, Francesco and Kalidindi, Hari Teja and Fruzzetti, Lorenzo and Laschi, Cecilia and Menciassi, Arianna and Falotico, Egidio},
  year = {2022},
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {5469--5476},
  issn = {2377-3766},
  doi = {10/gpt3cq},
  url = {https://ieeexplore.ieee.org/document/9730039},
  abstract = {Learning-based modeling and control of soft robots is advantageous due to neural network's ability to capture complex dynamical effects with low computational cost. Continual Learning techniques add further value to these methods by allowing networks to learn from continuously available data without incurring into catastrophic forgetting. In the context of soft robotic control, such capability can be exploited to design controllers able to continuously adapt to changes in robot dynamics, frequently due to material degradation or external interactions. This should be done without forgetting the control under normal working conditions which can be recovered as soon as the external interactions return to normal. In this letter elastic weight consolidation is used to continuously re-tune a neural network-based controller while changing the external loading of a soft robot. We demonstrate experimentally on a soft robot arm that this method outperforms plain stochastic gradient descent in tracking tasks, in the context of a continuously changing loading condition. We also show that the proposed control architecture can improve its performances when exposed to loading conditions already experienced. This letter represents a first step towards the introduction of continual learning methods in the soft robot control field.},
  keywords = {/unread,and learning for soft robots,Computational modeling,control,learning and adaptive systems,Loading,Mathematical models,Modeling,Robots,soft robot applications,Soft robotics,Task analysis,Training},
  annotation = {ZSCC:00005}
}

@incollection{thrun1995,
  title = {A {{Lifelong Learning Perspective}} for {{Mobile Robot Control}}},
  booktitle = {Intelligent {{Robots}} and {{Systems}}},
  author = {Thrun, Sebastian},
  editor = {Graefe, Volker},
  year = {1995},
  pages = {201--214},
  publisher = {{Elsevier Science B.V.}},
  address = {{Amsterdam}},
  doi = {10.1016/B978-044482250-5/50015-3},
  url = {http://www.sciencedirect.com/science/article/pii/B9780444822505500153},
  abstract = {Designing robots that learn by themselves to perform complex real-world tasks is a still-open challenge for the field of robotics and artificial intelligence. This chapter presents the robot learning problem as a lifelong problem, in which a robot faces a collection of tasks over its entire lifetime. Such a scenario provides the opportunity to gather general-purpose knowledge that transfers across tasks. The chapter illustrates a learning mechanism, explanation-based neural-network learning, that transfers knowledge between related tasks via neural-network action models. The learning approach is illustrated using a mobile robot, equipped with visual, ultrasonic, and laser sensors. In less than 10 minutes of operation time, the robot is able to learn to navigate to a marked target object in a natural office environment.},
  isbn = {978-0-444-82250-5},
  langid = {english},
  keywords = {/unread,\#nosource}
}

@article{wong2016,
  title = {Towards {{Lifelong Self-Supervision}}: {{A Deep Learning Direction}} for {{Robotics}}},
  author = {Wong, Jay M},
  year = {2016},
  journal = {arXiv},
  url = {http://arxiv.org/abs/1611.00201},
  abstract = {Despite outstanding success in vision amongst other domains, many of the recent deep learning approaches have evident drawbacks for robots. This manuscript surveys recent work in the literature that pertain to applying deep learning systems to the robotics domain, either as means of estimation or as a tool to resolve motor commands directly from raw percepts. These recent advances are only a piece to the puzzle. We suggest that deep learning as a tool alone is insufficient in building a unified framework to acquire general intelligence. For this reason, we complement our survey with insights from cognitive development and refer to ideas from classical control theory, producing an integrated direction for a lifelong learning architecture.},
  keywords = {/unread,\#nosource,⛔ No DOI found,autonomy,cognition,deep learning,lifelong learning,robotics},
  annotation = {\_eprint: 1611.00201}
}


